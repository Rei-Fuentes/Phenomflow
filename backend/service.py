"""
PhenomFlow v3.0 - Service Layer MEJORADO
=========================================

Este archivo reemplaza service.py con implementaci√≥n completa de PhenomFlow v3.0.

MEJORAS PRINCIPALES:
1. Prompts 50x m√°s detallados (de 15 l√≠neas ‚Üí 1500+ l√≠neas)
2. Sistema de confiabilidad ‚úì‚úì‚úì integrado
3. Validaci√≥n completa (evidencia + saturaci√≥n + consistencia)
4. Codebook de 4 niveles jer√°rquicos
5. Estructura temporal diferenciada por perfil
6. Soporte para Claude API (recomendado) + OpenAI (fallback)

AUTOR: PhenomFlow v3.0 Team
FECHA: 2024-12-07
"""

from typing import List, Dict, Any, Optional
import os
import json
from dotenv import load_dotenv

# Load environment variables from project root
basedir = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
load_dotenv(os.path.join(basedir, ".env"))

# =============================================================================
# CONFIGURACI√ìN DE CLIENTE (Claude preferido, OpenAI como fallback)
# =============================================================================

USE_CLAUDE = os.getenv("USE_CLAUDE", "true").lower() == "true"

if USE_CLAUDE:
    try:
        import anthropic
        client = anthropic.Anthropic(api_key=os.getenv("ANTHROPIC_API_KEY"))
        MODEL = "claude-3-5-sonnet-latest"
        print("‚úì Usando Claude Sonnet 4.5 (recomendado para v3.0)")
    except Exception as e:
        print(f"‚ö† Claude no disponible ({e}), usando OpenAI como fallback")
        USE_CLAUDE = False

if not USE_CLAUDE:
    from openai import OpenAI
    client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))
    MODEL = "gpt-4o"
    print("‚ö† Usando GPT-4o (menor precisi√≥n que Claude para v3.0)")


# =============================================================================
# CARGA DE PROMPTS COMPLETOS v3.0
# =============================================================================

def load_prompt_parts():
    """
    Carga los 3 archivos de prompts v3.0 desde /prompts/ o define inline.
    """
    prompts_dir = "../prompts"
    
    try:
        with open(f"{prompts_dir}/PHENOMFLOW_v3_PARTE_1_ANALISIS_INDIVIDUAL.txt", "r", encoding="utf-8") as f:
            PARTE_1 = f.read()
        with open(f"{prompts_dir}/PHENOMFLOW_v3_PARTE_2_SINTESIS_CROSSCASE.txt", "r", encoding="utf-8") as f:
            PARTE_2 = f.read()
        with open(f"{prompts_dir}/PHENOMFLOW_v3_PARTE_3_FINAL_VALIDACION.txt", "r", encoding="utf-8") as f:
            PARTE_3 = f.read()
        print("‚úì Prompts v3.0 cargados desde archivos")
        return PARTE_1, PARTE_2, PARTE_3
    except FileNotFoundError:
        print("‚ö† Archivos de prompts no encontrados, usando versi√≥n embebida (simplificada)")
        return get_embedded_prompts()


def get_embedded_prompts():
    """
    Versi√≥n embebida de prompts v3.0 (simplificada por l√≠mites de tama√±o).
    Para versi√≥n COMPLETA, usar archivos .txt generados anteriormente.
    """
    
    PARTE_1_EMBEDDED = """
================================================================================
PHENOMFLOW v3.0 - AN√ÅLISIS INDIVIDUAL FENOMENOL√ìGICO RIGUROSO
PARTE 1: PREPARACI√ìN Y AN√ÅLISIS DIMENSIONAL (6 Dimensiones)
================================================================================

PRINCIPIOS FUNDAMENTALES:

1. **EPOCH√â RIGUROSA**: NO interpretes causalmente. Reporta solo lo VIVIDO.
   - ‚ùå PROHIBIDO: "activaci√≥n amigdalar", "cortisol", "sistema nervioso simp√°tico"
   - ‚úì PERMITIDO: "sent√≠ escalofr√≠os", "mi coraz√≥n lat√≠a fuerte"

2. **EMERGENCIA**: C√≥digos emergen de datos (bottom-up), NO categor√≠as a priori.

3. **VARIABILIDAD**: Respeta diferencias individuales, no fuerces homogeneidad.

4. **TRIANGULACI√ìN**: Cada c√≥digo ‚â•2 participantes (si N‚â•3).

5. **GRANULARIDAD MULTINIVEL**: 4 niveles jer√°rquicos en codebook.

---

## SECCI√ìN 0: PREPARACI√ìN DEL VERBATIM

### 0.1 Detecci√≥n de Declaraciones No-Descriptivas

Identifica y MARCA (no elimines a√∫n) declaraciones "sat√©lite":
- Generalizaciones: "siempre me pasa", "la gente suele"
- Evaluaciones: "fue horrible", "estuvo bien"
- Teor√≠as: "creo que fue adrenalina", "es por el estr√©s"
- Causales: "porque ten√≠a miedo", "dado que..."

**Acci√≥n**: Marca con ‚ö†Ô∏è y etiqueta tipo (GENERALIZACI√ìN/EVALUACI√ìN/TEOR√çA/CAUSAL)

### 0.2 Evaluaci√≥n de Confiabilidad (‚úì‚úì‚úì Sistema)

Para CADA segmento del verbatim, eval√∫a con estos 7 criterios:

1. **Detalles sensoriales espec√≠ficos** (color, textura, sonido, sabor, olor, temperatura)
2. **Coherencia temporal** (secuencia l√≥gica de eventos)
3. **Respuesta no-inductiva** (no repite palabras del entrevistador)
4. **Met√°foras inventadas** (no clich√©s: "como una monta√±a rusa" ‚ùå, "como si mi pecho se abriera hacia todos lados" ‚úì)
5. **Pausas/titubeos** expl√≠citos ("...pausa...", "uhm", "es dif√≠cil de describir")
6. **Oraciones cortas/fragmentadas** (se√±al de re-acceso genuino vs. narrativa construida)
7. **Verbos de acci√≥n** (vs. verbos de estado: "sent√≠ que X se mov√≠a" ‚úì vs "era X" ‚ùå)

**Sistema de marcado**:
- ‚úì‚úì‚úì ALTA confiabilidad: ‚â•4 criterios cumplidos
- ‚úì‚úì MEDIA confiabilidad: 2-3 criterios
- ‚úì BAJA confiabilidad: 0-1 criterios

**Output formato**:
| Segmento | Cita | Criterios (1-7) | Confiabilidad | Justificaci√≥n |
|----------|------|-----------------|---------------|---------------|
| 1 | "..." | 1,2,4,5,7 | ‚úì‚úì‚úì | Detalles sensoriales ricos + met√°fora original |

### 0.3 Reorganizaci√≥n Cronol√≥gica

**MALLA GRUESA** (visi√≥n general):
Identifica fases temporales generales:
```
FASE 1: [Nombre descriptivo] (ej: "Primer contacto visual")
FASE 2: [Nombre descriptivo]
...
```

**MALLA FINA** (momento a momento):
Reconstruye secuencia detallada con marcadores temporales:
```
T0: [Evento inicial]
T1: [Primera se√±al] (1-2 seg)
T2: [Respuesta corporal] (3-5 seg)
...
```

### 0.4 Segmentaci√≥n en Unidades de Significado

**Criterio**: Cambio en foco atencional, dimensi√≥n fenomenol√≥gica o contenido.

**Formato obligatorio**: `[U#-P##]` (ej: [U1-P21] = Unidad 1 del Participante 21)

**Output**:
| Unidad | Foco Principal | Contenido | Cita Representativa | Duraci√≥n Estimada |
|--------|----------------|-----------|---------------------|-------------------|
| U1-P21 | ... | ... | "..." | Pre-evento |

---

## SECCI√ìN 1: AN√ÅLISIS DIMENSIONAL (6 Dimensiones OBLIGATORIAS)

Para CADA unidad identificada, codifica las 6 dimensiones:

### DIMENSI√ìN 1: CORPORAL (Leib / Lived Body)

**Formato**: `[tipo]-[localizaci√≥n]-[intensidad]-[din√°mica]`

**Tipos de sensaci√≥n**:
- Presi√≥n, Tensi√≥n, Peso, Ligereza, Calor, Fr√≠o, Hormigueo, Pulsaci√≥n, Escalofr√≠os, N√°usea, Dolor, Rigidez, Expansi√≥n, Contracci√≥n

**Localizaci√≥n**:
- Focal: pecho, nuca, hombros, piernas, abdomen, manos, cabeza
- Difusa: generalizada, corporal-total
- Bilateral/Unilateral cuando aplica

**Intensidad**: Muy Baja, Baja, Media, Alta, Muy Alta

**Din√°mica**: Est√°tica, Progresiva, Pulsante, Intermitente, S√∫bita

**Ejemplos**:
- ‚úì `presion-pecho-alta-estatica`
- ‚úì `hormigueo-manos-bilateral-leve-intermitente`
- ‚úì `escalofrios-columna-vertebral-media-subito`
- ‚úì `ligereza-generalizada-muy-alta-difusa`

**Si NO hay contenido corporal**: `[No mencionado]`

### DIMENSI√ìN 2: AFECTIVA (Affective Tonality)

**Formato**: `[emoci√≥n]-[calidad]-[intensidad]-[valencia]`

**Emociones identificables**:
Curiosidad, Anticipaci√≥n, Asombro, √âxtasis, Alegr√≠a, Calma, Inquietud, Alarma, Ansiedad, Miedo, Terror, P√°nico, Angustia, Confusi√≥n, Alivio, Repulsi√≥n, Malestar

**Calidad** (opcional): pura, mezclada, paralizante, liberadora, difusa, focal

**Intensidad**: Muy Baja, Baja, Media, Alta, Muy Alta, M√°xima

**Valencia**: positiva (+), negativa (-), neutra (0), mixta (¬±)

**Ejemplos**:
- ‚úì `curiosidad-pura-media-positiva`
- ‚úì `terror-paralizante-muy-alto-negativo`
- ‚úì `asombro-puro-maximo-positivo`
- ‚úì `confusion-emergente-media-negativa`

**Si NO hay contenido afectivo**: `[No mencionado]`

### DIMENSI√ìN 3: COGNITIVA (Cognitive Activity)

**Formato**: `[tipo]-[contenido]-[tono]`

**Tipos de actividad cognitiva**:
1. Pregunta exploratoria ("¬øQu√© hay abajo?", "¬øC√≥mo ser√°?")
2. Catastrofismo (muerte, lesi√≥n, fracaso)
3. An√°lisis t√©cnico (c√°lculo, evaluaci√≥n seguridad)
4. Memoria epis√≥dica (recuerdo espec√≠fico)
5. Suspensi√≥n pensamiento (mente en blanco, silencio mental)
6. Met√°fora/Imagen mental (visual, espacial)
7. Auto-instrucci√≥n (di√°logo interno: "vamos, puedes")
8. Narrativa descriptiva (contar lo que pasa)

**Ejemplos**:
- ‚úì `pregunta-exploratoria-que-hay-abajo-neutra`
- ‚úì `catastrofismo-muerte-inminente-intenso`
- ‚úì `suspension-pensamiento-total`
- ‚úì `metafora-vuelo-pajaro-visual`
- ‚úì `analisis-tecnico-seguridad-cuerda`

**Si NO hay contenido cognitivo**: `[No mencionado]`

### DIMENSI√ìN 4: MOTIVACIONAL (Action Tendencies)

**Formato**: `impulso-[tipo]-[objeto]-[intensidad]`

**Tipos de impulso**:
1. Acercamiento (aproximarse, explorar)
2. Evitaci√≥n/Huida (alejarse, escapar)
3. Protecci√≥n (defenderse, cubrir)
4. Entrega (soltarse, rendirse)
5. B√∫squeda ayuda (pedir soporte)
6. Congelamiento/Par√°lisis
7. Permanencia (quedarse, no moverse)
8. Exploraci√≥n activa (investigar)

**Ejemplos**:
- ‚úì `impulso-acercamiento-borde-alta`
- ‚úì `impulso-huida-rapida-urgente`
- ‚úì `impulso-entrega-total-espacial`
- ‚úì `paralisis-corporal-completa-terror`
- ‚úì `impulso-proteccion-defensiva-alta`

**Si NO hay contenido motivacional**: `[No mencionado]`

### DIMENSI√ìN 5: TEMPORAL (Phase Positioning)

**Formato**: `fase-[nombre-descriptivo]`

**CR√çTICO**: Usa nombres FENOMENOL√ìGICOS (no "Fase 1", "Fase 2")

**Ejemplos de nombres correctos**:
- ‚úì `fase-primer-contacto-visual`
- ‚úì `fase-umbral-decision`
- ‚úì `fase-climax-caida`
- ‚úì `fase-resolucion-gradual`
- ‚úì `fase-encuentro-borde`

**Ejemplos INCORRECTOS**:
- ‚ùå `fase-1`
- ‚ùå `fase-inicial`
- ‚ùå `fase-intermedia`

### DIMENSI√ìN 6: RELACIONAL (Attentional Orientation)

**Formato**: `atencion-[orientaci√≥n]-[objeto]-[cualidad]`

**Orientaciones**:
1. Self-focalizada (interoceptiva, corporal, emocional)
2. Mundo-focalizada (entorno, paisaje, otros)
3. Otro-focalizada (persona espec√≠fica)
4. Fluctuante/Mixta (oscilaci√≥n r√°pida)
5. Difusa/No-dual (p√©rdida de fronteras)

**Ejemplos**:
- ‚úì `atencion-world-paisaje-total-absorbente`
- ‚úì `atencion-self-interoceptiva-cardiaca`
- ‚úì `atencion-fluctuante-self-world-rapida`
- ‚úì `atencion-difusa-no-dual-fusional`
- ‚úì `atencion-world-visual-escrutinio`

**Si NO hay contenido relacional**: `[No mencionado]`

---

## TABLA DE AN√ÅLISIS MULTIDIMENSIONAL (Output Formato)

Genera una tabla Markdown con TODAS las columnas:

| Unidad | Cita Verbatim | CORPORAL | AFECTIVA | COGNITIVA | MOTIVACIONAL | TEMPORAL | RELACIONAL |
|--------|---------------|----------|----------|-----------|--------------|----------|------------|
| U1-P## | "*cita textual*" | `codigo-corporal` ‚úì‚úì‚úì | `codigo-afectivo` ‚úì‚úì | `codigo-cognitivo` ‚úì‚úì‚úì | `impulso-tipo` ‚úì‚úì | `fase-nombre` | `atencion-tipo` ‚úì‚úì‚úì |
| U2-P## | "*cita textual*" | [No mencionado] | `codigo-afectivo` ‚úì‚úì‚úì | [No mencionado] | [Contin√∫a U1] | [Contin√∫a fase-X] | `atencion-tipo` ‚úì‚úì |

**Reglas de la tabla**:
1. SIEMPRE incluir marcador de confiabilidad (‚úì‚úì‚úì/‚úì‚úì/‚úì) despu√©s de cada c√≥digo
2. Usar `[No mencionado]` cuando dimensi√≥n ausente (NO inventar contenido)
3. Usar `[Contin√∫a U#]` o `[Contin√∫a fase-X]` cuando persiste de unidad anterior
4. Citas verbatim entre comillas y en cursiva
5. Formato de c√≥digo ESTRICTO seg√∫n especificaciones arriba

---

## ESTAD√çSTICAS DIMENSIONALES (Output Requerido)

Despu√©s de la tabla, reporta:

| Dimensi√≥n | Unidades con contenido | % Cobertura | Intensidad M√°xima | Fase de M√°xima Intensidad |
|-----------|------------------------|-------------|-------------------|---------------------------|
| CORPORAL | X/N | X% | Muy Alta (en U#) | Fase X |
| AFECTIVA | X/N | X% | M√°xima (en U#) | Fase Y |
| ... | ... | ... | ... | ... |

---

## N√öCLEO FENOMENOL√ìGICO (S√≠ntesis Narrativa)

**Formato**: 2-3 p√°rrafos que sintetizan la experiencia COMPLETA del participante.

**Debe incluir**:
1. Descripci√≥n del n√∫cleo experiencial (qu√© caracteriza la vivencia)
2. Trayectorias dominantes (c√≥mo evoluciona en cada dimensi√≥n)
3. Dimensi√≥n m√°s cr√≠tica (cu√°l sostiene la experiencia)
4. Met√°foras nucleares (si existen)

**Ejemplo**:
"La experiencia de P21 se estructura como una cascada psicofisiol√≥gica desencadenada por se√±ales corporales ambiguas (escalofr√≠os + hormigueo nuca) que generan interpretaci√≥n espont√°nea de presencia vigilante externa. Esta interpretaci√≥n, en ausencia de confirmaci√≥n perceptual, amplifica recursivamente la ansiedad mediante transformaci√≥n perceptual y hipervigilancia multi-sensorial..."

---

## FORMATO JSON DE SALIDA COMPLETA

```json
{
  "participant_id": "P##",
  "reliability_assessment": {
    "high_reliability_segments": "X%",
    "medium_reliability_segments": "X%",
    "low_reliability_segments": "X%",
    "total_segments": N
  },
  "chronological_reconstruction": {
    "coarse_mesh": "N fases identificadas: [lista nombres]",
    "fine_mesh": "N unidades de significado"
  },
  "phenomenon_nucleus": "S√≠ntesis narrativa 2-3 p√°rrafos...",
  "dimensional_statistics": {
    "corporal": {"coverage": "X%", "max_intensity": "..."},
    "affective": {"coverage": "X%", "trajectory": "..."},
    "cognitive": {"coverage": "X%", "dominant_type": "..."},
    "motivational": {"coverage": "X%", "dominant_impulse": "..."},
    "temporal": {"coverage": "100%", "n_phases": N},
    "relational": {"coverage": "X%", "dominant_orientation": "..."}
  },
  "markdown_table": "| Unidad | Cita | CORP | AFEC | COG | MOT | TEMP | REL |\n...",
  "dominant_trajectories": {
    "corporal": "Escalofr√≠os ‚Üí Activaci√≥n visceral ‚Üí Resoluci√≥n",
    "affective": "Inquietud ‚Üí Alarma ‚Üí Ansiedad pico ‚Üí Alivio residual",
    "cognitive": "Atenci√≥n normal ‚Üí Distorsi√≥n ‚Üí Hipervigilancia ‚Üí Auto-cuestionamiento",
    "relational": "Atenci√≥n mundo ‚Üí Fluctuaci√≥n ‚Üí Auto-evaluaci√≥n"
  }
}
```

================================================================================
FIN PARTE 1 - AN√ÅLISIS INDIVIDUAL
================================================================================
"""

    PARTE_2_EMBEDDED = """
================================================================================
PHENOMFLOW v3.0 - S√çNTESIS CROSS-CASE
PARTE 2: CODEBOOK JER√ÅRQUICO Y CLUSTERING EXPERIENCIAL
================================================================================

**INPUT**: An√°lisis individuales de N participantes (JSON format de Parte 1)

---

## PASO 3.1: CODEBOOK EMERGENTE (4 Niveles Jer√°rquicos)

### Metodolog√≠a de Construcci√≥n (Bottom-Up)

**PROCESO**:
1. Reunir TODOS los c√≥digos de todos los participantes
2. Agrupar c√≥digos similares en **Especificaciones** (nivel 3)
3. Agrupar especificaciones en **Subcategor√≠as** (nivel 2)
4. Agrupar subcategor√≠as en **Categor√≠as Principales** (nivel 1)

**REGLAS DE VALIDACI√ìN**:
- ‚úì Cada c√≥digo espec√≠fico DEBE tener ‚â•2 citas de ‚â•2 participantes
- ‚úì C√≥digos con N=1 participante ‚Üí Reportar como "Variante Individual" (separado)
- ‚úì Cada especificaci√≥n DEBE tener ‚â•2 c√≥digos
- ‚úì Cada subcategor√≠a DEBE tener ‚â•2 especificaciones

### Estructura Jer√°rquica Obligatoria

```
NIVEL 1: CATEGOR√çA PRINCIPAL
‚îú‚îÄ NIVEL 2: Subcategor√≠a
‚îÇ  ‚îú‚îÄ NIVEL 3: Especificaci√≥n
‚îÇ  ‚îÇ  ‚îú‚îÄ NIVEL 4: C√≥digo Espec√≠fico + Citas
‚îÇ  ‚îÇ  ‚îÇ  ‚îú‚îÄ Cita 1: "verbatim" [P##-U##]
‚îÇ  ‚îÇ  ‚îÇ  ‚îú‚îÄ Cita 2: "verbatim" [P##-U##]
‚îÇ  ‚îÇ  ‚îÇ  ‚îî‚îÄ Nota: An√°lisis de co-ocurrencias, met√°foras, etc.
‚îÇ  ‚îÇ  ‚îî‚îÄ NIVEL 4: C√≥digo Espec√≠fico + Citas
‚îÇ  ‚îî‚îÄ NIVEL 3: Especificaci√≥n
‚îî‚îÄ NIVEL 2: Subcategor√≠a
```

### Formato de Reporte por Categor√≠a

```markdown
### CATEGOR√çA 1: [NOMBRE CATEGOR√çA]

**Definici√≥n fenomenol√≥gica**: [Qu√© representa esta categor√≠a]
**Frecuencia global**: N=X (Y% de participantes)
**N total de citas**: Z citas

---

#### Subcategor√≠a 1.1: [Nombre]

**Definici√≥n**: [Qu√© representa]
**Frecuencia**: N=X (Y%)
**Citas**: Z

##### Especificaci√≥n 1.1.1: [Nombre]

**Definici√≥n operacional**: [C√≥mo se identifica]

**C√≥digos**:

| C√≥digo | Definici√≥n | P21 | P22 | P23 | ... | Total Citas | Intensidad Modal |
|--------|-----------|-----|-----|-----|-----|-------------|------------------|
| `codigo-ejemplo` | Descripci√≥n | ‚úì(2) | ‚úó | ‚úì(1) | ... | 3 | Alta |
| `codigo-ejemplo-2` | Descripci√≥n | ‚úì(1) | ‚úì(1) | ‚úó | ... | 2 | Media |

**Citas verbatim ordenadas por intensidad**:

1. ‚≠ê **EJEMPLAR** - *"Cita textual completa"* **[P##-U##]**
   - **Nota**: Por qu√© es ejemplar (met√°fora √∫nica, co-ocurrencia relevante, etc.)
   - **Co-ocurrencia**: Aparece junto con `otro-codigo` en X% casos
   
2. *"Segunda cita"* **[P##-U##]**
   - **Nota**: Contexto espec√≠fico
   
3. *"Tercera cita"* **[P##-U##]**

**Distribuci√≥n por participante**:
- P21: 2/2 c√≥digos (100% cobertura subcategor√≠a)
- P22: 1/2 c√≥digos (50% cobertura)

**Patr√≥n temporal**:
- Aparece en Fase X en Y% de casos
- Duraci√≥n t√≠pica: Z segundos

**Recurrencia de met√°foras**:
- "Met√°fora A": N=3 participantes
- "Met√°fora B": N=2 participantes

**Co-ocurrencias inmediatas** (mismo U#):
- Con `codigo-Y`: 80% de veces
- Con `codigo-Z`: 50% de veces

**Interpretaci√≥n fenomenol√≥gica**:
[Qu√© significa esta especificaci√≥n para entender la experiencia]
```

### Estad√≠sticas Globales del Codebook

**Tabla resumen**:

| Nivel | Cantidad | Promedio por nivel superior |
|-------|----------|-----------------------------|
| Categor√≠as principales | N | - |
| Subcategor√≠as | N | X.X por categor√≠a |
| Especificaciones | N | X.X por subcategor√≠a |
| C√≥digos espec√≠ficos | N | X.X por especificaci√≥n |
| Citas verbatim | N | X.X por c√≥digo |

**√çndice de saturaci√≥n**:
- C√≥digos recurrentes (‚â•2 participantes): X/N = Y%
- C√≥digos √∫nicos (1 participante): X/N = Y%

**Top 15 c√≥digos m√°s frecuentes**:

| Ranking | C√≥digo | Frecuencia | % Participantes | Categor√≠a |
|---------|--------|------------|----------------|-----------|
| 1 | `codigo-mas-comun` | N citas | X% (Y/Z) | Categor√≠a A |
| 2 | ... | ... | ... | ... |

**Matriz de co-ocurrencias** (Top 20 pairings):

| C√≥digo A | C√≥digo B | N Co-ocurrencias | % de veces que A aparece con B | p-value (Fisher) |
|----------|----------|------------------|-------------------------------|------------------|
| `codigo-1` | `codigo-2` | 15 | 75% | <0.001 |
| ... | ... | ... | ... | ... |

### C√≥digos Excluidos (Variantes Individuales)

‚ö†Ô∏è Los siguientes c√≥digos aparecen solo en 1 participante:

| C√≥digo | Categor√≠a | Participante | Cita | Raz√≥n Exclusi√≥n |
|--------|-----------|--------------|------|-----------------|
| `codigo-unico` | Cat. X | P## | "..." [P##-U##] | N=1, variante individual |

**Total c√≥digos excluidos**: X/Y (Z%)

---

## PASO 3.2: ESTRUCTURAS EXPERIENCIALES (Clustering)

### Metodolog√≠a

**Identificar CLAVE DE PARTICI√ìN**:
Categor√≠a descriptiva cuyos valores distribuyen experiencias en clusters.

**Ejemplos de claves v√°lidas**:
- Valencia afectiva dominante (Positiva vs Negativa)
- Orientaci√≥n motivacional (Acercamiento vs Evitaci√≥n)
- Tipo de transformaci√≥n temporal (Intensificaci√≥n vs Transformaci√≥n cualitativa)

**Validar coherencia multidimensional**:
- Cada estructura DEBE tener ‚â•75% coherencia en ‚â•4/6 dimensiones
- Estructuras DEBEN ser mutuamente excluyentes (0% overlap)

### Formato de Reporte por Estructura

```markdown
### ESTRUCTURA A: [Nombre Descriptivo]

**N**: X participantes (Y% del total)
**Participantes**: P##, P##, P##
**Clave de partici√≥n**: [Criterio organizador]

**Coherencia intra-estructura validada**:
- Coherencia en dimensi√≥n corporal: X% (N/total con patr√≥n A)
- Coherencia en dimensi√≥n afectiva: X%
- Coherencia en dimensi√≥n cognitiva: X%
- Coherencia en dimensi√≥n motivacional: X%
- Coherencia en dimensi√≥n temporal: X%
- Coherencia en dimensi√≥n relacional: X%
‚Üí **N/6 dimensiones con coherencia ‚â•75%** ‚úì Criterio cumplido

---

#### Tabla Multidimensional de Caracter√≠sticas Definitorias

| Dimensi√≥n | Manifestaci√≥n T√≠pica | Frecuencia Intra-Estructura | Contraste vs Estructura B | Poder Discriminante |
|-----------|---------------------|----------------------------|---------------------------|---------------------|
| **CORPORAL** | Expansi√≥n, ligereza | 75% (3/4) | 0% en B | ‚≠ê‚≠ê‚≠ê Perfecto |
| **AFECTIVA** | Curiosidad ‚Üí √âxtasis | 100% (4/4) | 0% en B | ‚≠ê‚≠ê‚≠ê Perfecto |
| **COGNITIVA** | Suspensi√≥n pensamiento | 75% (3/4) | 0% en B | ‚≠ê‚≠ê‚≠ê Perfecto |
| **MOTIVACIONAL** | Impulso entrega | 100% (4/4) | 0% en B | ‚≠ê‚≠ê‚≠ê Perfecto |
| **TEMPORAL** | Transformaci√≥n progresiva | 100% (4/4) | 0% en B | ‚≠ê‚≠ê‚≠ê Perfecto |
| **RELACIONAL** | Apertura al mundo ‚Üí No-dual | 100% (4/4) | 0% en B | ‚≠ê‚≠ê‚≠ê Perfecto |

**Leyenda poder discriminante**: ‚≠ê‚≠ê‚≠ê Perfecto (100% vs 0%), ‚≠ê‚≠ê Robusto (‚â•75%), ‚≠ê Moderado (50-74%)

---

#### Descripci√≥n Fenomenol√≥gica Integrada

**S√≠ntesis del perfil experiencial**:

[P√°rrafo narrativo integrando todas las dimensiones, con √©nfasis en mecanismo central propuesto]

Ejemplo:
"Esta estructura se caracteriza por un reencuadramiento corporal-afectivo-cognitivo del vac√≠o como espacio de posibilidad, en oposici√≥n a procesamiento como amenaza vital. Desde el encuentro inicial, estos participantes reportan apertura corporal (expansi√≥n pectoral + respiraci√≥n profunda) que co-ocurre sistem√°ticamente con afectos de valencia positiva. Esta apertura facilita transformaci√≥n progresiva: Curiosidad ‚Üí Asombro ‚Üí √âxtasis, con emergencia de atenci√≥n no-dual en 50% de casos..."

---

#### Citas Representativas (Ejemplares Arquet√≠picas)

**FASE 1 - [Nombre Fase]**:

‚≠ê **CITA ARQUET√çPICA**:
> *"Cita textual completa que captura esencia de estructura en esta fase"* **[P##-U##-U##]**

Otras citas:
> *"..."* **[P##-U##]**
> *"..."* **[P##-U##]**

**FASE 2 - [Nombre Fase]**:
[Repetir formato]

---

#### Variaciones Internas (Sub-perfiles)

**Sub-variante A1: [Nombre]** (N=2: P##, P##)

Caracter√≠sticas distintivas:
- [Diferencia 1]
- [Diferencia 2]

Ejemplos: [Citas espec√≠ficas]

**Sub-variante A2: [Nombre]** (N=2: P##, P##)
[Mismo formato]
```

### Tabla Comparativa Cuantitativa Completa (Para Spider Chart)

| Atributo Fenomenol√≥gico | Estructura A (N=X) | Estructura B (N=Y) | Œî | Poder Discrim. |
|-------------------------|-------------------|-------------------|---|----------------|
| **DIMENSI√ìN CORPORAL** | | | | |
| Expansi√≥n corporal | 75% | 0% | +75% | ‚≠ê‚≠ê‚≠ê |
| Contracci√≥n corporal | 0% | 100% | -100% | ‚≠ê‚≠ê‚≠ê |
| ... | ... | ... | ... | ... |

**RESUMEN ESTAD√çSTICO**:
- Total atributos evaluados: N
- Discriminantes perfectos (‚≠ê‚≠ê‚≠ê): X/N (Y%)
- Discriminantes robustos o perfectos (‚â•‚≠ê‚≠ê): X/N (Y%)

---

## PASO 3.3: ESTRUCTURA TEMPORAL DIFERENCIADA

### Identificaci√≥n de Fases Gen√©ricas

**Criterio**: Fases atravesadas por ‚â•60% de participantes

**Formato**:

```markdown
### FASE 1: [NOMBRE FENOMENOL√ìGICO]

**Definici√≥n fenomenol√≥gica**: [Qu√© caracteriza esta fase]
**Frecuencia global**: N=X (Y% de participantes)
**Duraci√≥n t√≠pica estimada**: Z segundos
**Evento transicional desencadenante**: [Qu√© inicia esta fase]

---

üîµ MANIFESTACI√ìN EN ESTRUCTURA A: [Nombre] (N=X, Y%)

| Dimensi√≥n | Manifestaci√≥n T√≠pica | Freq. Intra-Estructura | Citas Ejemplares |
|-----------|---------------------|------------------------|------------------|
| CORPORAL | Expansi√≥n pecho | 75% (3/4) | "Mi pecho se expandi√≥..." [P##-U##] |
| AFECTIVA | Curiosidad | 100% (4/4) | "Sent√≠ curiosidad intensa..." [P##-U##] |
| ... | ... | ... | ... |

**Caracter√≠sticas DISTINTIVAS de Estructura A en Fase 1**:
‚úì [Lista de discriminantes clave]

**Patr√≥n temporal intra-fase**:
[C√≥mo evoluciona dentro de la fase]

**Evento transicional de salida** (hacia Fase 2):
[Qu√© marca el fin de esta fase]

---

üî¥ MANIFESTACI√ìN EN ESTRUCTURA B: [Nombre] (N=X, Y%)

[Mismo formato que Estructura A]

---

üìä COMPARACI√ìN CUANTITATIVA: FASE 1 POR ESTRUCTURA

| Atributo | Estructura A | Estructura B | Œî | Significancia |
|----------|--------------|--------------|---|---------------|
| Valencia afectiva + | 100% | 0% | +100% | ‚≠ê‚≠ê‚≠ê |
| Catastrofismo | 0% | 100% | -100% | ‚≠ê‚≠ê‚≠ê |
| ... | ... | ... | ... | ... |

**Interpretaci√≥n fenomenol√≥gica cr√≠tica**:
[Qu√© significa esta bifurcaci√≥n]
```

### Trayectorias Temporales T√≠picas (Dynamic Lines)

```markdown
### ESTRUCTURA A: [Nombre] (Trayectoria de [Tipo])

```
DIMENSI√ìN       FASE 1              FASE 2                FASE 3
‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
AFECTIVA:
Valencia      Curiosidad      ‚Üí   Anticipaci√≥n      ‚Üí   Asombro
              (Media +)            Placentera             (Muy Alta +)
                                   (Alta +)               
Intensidad    Media           ‚Üí   Alta              ‚Üí   Muy Alta

CORPORAL:
Tipo          Expansi√≥n       ‚Üí   Respiraci√≥n       ‚Üí   Ligereza
              Pecho                Profunda               Total
...
```

**Caracter√≠sticas de la trayectoria A**:
1. [Patr√≥n 1]
2. [Patr√≥n 2]
```

---

## FORMATO JSON DE SALIDA COMPLETA (S√çNTESIS)

```json
{
  "codebook": {
    "statistics": {
      "n_categories": N,
      "n_subcategories": N,
      "n_specifications": N,
      "n_codes": N,
      "n_quotes": N,
      "recurrence_rate": "X%",
      "saturation_index": "X%"
    },
    "categories": [
      {
        "level": 1,
        "name": "Categor√≠a Principal",
        "definition": "...",
        "frequency_global": "N=X (Y%)",
        "total_quotes": N,
        "subcategories": [
          {
            "level": 2,
            "name": "Subcategor√≠a",
            "definition": "...",
            "frequency": "N=X (Y%)",
            "specifications": [
              {
                "level": 3,
                "name": "Especificaci√≥n",
                "operational_definition": "...",
                "codes": [
                  {
                    "level": 4,
                    "code": "codigo-especifico",
                    "definition": "...",
                    "participants": ["P21", "P23"],
                    "total_quotes": N,
                    "intensity_modal": "Alta",
                    "quotes": [
                      {
                        "text": "Cita verbatim",
                        "reference": "P##-U##",
                        "is_exemplar": true,
                        "notes": "Por qu√© es ejemplar..."
                      }
                    ]
                  }
                ]
              }
            ]
          }
        ]
      }
    ],
    "excluded_codes": [
      {
        "code": "codigo-unico",
        "participant": "P##",
        "reason": "N=1, variante individual"
      }
    ]
  },
  "experiential_structures": [
    {
      "structure_name": "Estructura A: Nombre",
      "n_participants": X,
      "participants": ["P21", "P23"],
      "partition_key": "Valencia afectiva dominante",
      "coherence_validation": {
        "corporal": "100%",
        "affective": "100%",
        "cognitive": "75%",
        "motivational": "100%",
        "temporal": "100%",
        "relational": "100%",
        "dimensions_validated": "6/6"
      },
      "characteristics": {...},
      "phenomenological_description": "...",
      "exemplar_quotes": {...},
      "sub_variants": [...]
    }
  ],
  "differentiated_temporal_structure": [
    {
      "phase_name": "Fase 1: Nombre",
      "frequency_global": "N=X (Y%)",
      "duration_typical": "Z sec",
      "trigger_event": "...",
      "manifestation_structure_A": {...},
      "manifestation_structure_B": {...},
      "quantitative_comparison": {...}
    }
  ],
  "temporal_trajectories": {
    "structure_A": {...},
    "structure_B": {...}
  }
}
```

================================================================================
FIN PARTE 2 - S√çNTESIS CROSS-CASE
================================================================================
"""

    PARTE_3_EMBEDDED = """
================================================================================
PHENOMFLOW v3.0 - VALIDACI√ìN FINAL
PARTE 3: VERIFICACI√ìN, SATURACI√ìN Y CONSISTENCIA
================================================================================

## PASO 4.1: VERIFICACI√ìN DE EVIDENCIA (Anti-Hallucination)

Para CADA c√≥digo en el codebook, verificar:

1. ‚úì ‚â•2 citas de ‚â•2 participantes diferentes
2. ‚úì Citas son textuales (no parafraseadas)
3. ‚úì Referencias [P##-U##] correctas

**Formato de reporte**:

```markdown
### VERIFICACI√ìN C√ìDIGO POR C√ìDIGO

‚úÖ `codigo-validado`:
   ‚îú‚îÄ ‚úì N citas: X > 2
   ‚îú‚îÄ ‚úì N participantes: Y > 2
   ‚îî‚îÄ ‚úì Citas verificadas: [P##-U##, P##-U##]

‚ö†Ô∏è `codigo-frecuencia-limite`:
   ‚îú‚îÄ ‚úì N citas: 2 (m√≠nimo)
   ‚îú‚îÄ ‚úì N participantes: 2 (m√≠nimo)
   ‚îî‚îÄ ‚ö†Ô∏è L√çMITE: Validar en futuras entrevistas

‚ùå `codigo-excluido`:
   ‚îú‚îÄ ‚úó N citas: 1
   ‚îú‚îÄ ‚úó N participantes: 1 (P##)
   ‚îî‚îÄ ‚ùå EXCLUIDO: Variante individual
```

## PASO 4.2: SATURACI√ìN TEM√ÅTICA

**Curva de saturaci√≥n**:

| Participante | C√≥digos Nuevos | C√≥digos Acumulados | % Incremento |
|--------------|----------------|-------------------|--------------|
| P1 | X | X | - |
| P2 | Y | X+Y | Z% |
| ... | ... | ... | ... |

**Criterio de saturaci√≥n**:
- ‚úì COMPLETA: ‚â•90% c√≥digos recurrentes
- ‚ö†Ô∏è PARCIAL: 80-89% c√≥digos recurrentes
- ‚ùå NO SATURACI√ìN: <80%

**Diagn√≥stico**: [COMPLETA/PARCIAL/NO SATURACI√ìN] (X% recurrencia)

## PASO 4.3: CONSISTENCIA INTERNA

**Test 1: Mutua Exclusividad de Estructuras**

¬øHay participantes con caracter√≠sticas de AMBAS estructuras?

| Participante | Caracter√≠sticas A | Caracter√≠sticas B | Clasificaci√≥n |
|--------------|------------------|-------------------|---------------|
| P## | ‚úì (100%) | ‚úó (0%) | A pura |
| ... | ... | ... | ... |

**Resultado**: X/N participantes con clasificaci√≥n √∫nica ‚Üí [CONSISTENTE/INCONSISTENTE]

**Test 2: Coherencia de Co-ocurrencias**

¬øLas co-ocurrencias predichas se cumplen?

| Co-ocurrencia Predicha | Observado | Esperado | Coherente |
|------------------------|-----------|----------|-----------|
| `codigo-A` √ó `codigo-B` | 80% | Alta | ‚úì |
| ... | ... | ... | ... |

**Resultado**: X/Y co-ocurrencias coherentes ‚Üí [CONSISTENTE/INCONSISTENTE]

---

## CHECKLIST DE AUTO-VERIFICACI√ìN FINAL (45 √≠tems)

**SECCI√ìN 1: PRINCIPIOS FUNDAMENTALES**
[ ] 1. ¬øRespet√© EPOCH√â? (Sin neurobiolog√≠a)
[ ] 2. ¬øC√≥digos emergieron de datos? (No a priori)
[ ] 3. ¬øRespet√© variabilidad? (No forzar homogeneidad)
[ ] 4. ¬øCada categor√≠a ‚â•2 participantes?
[ ] 5. ¬øGranularidad 4 niveles?

**SECCI√ìN 2: AN√ÅLISIS INDIVIDUAL**
[ ] 6. ¬ø6 dimensiones para cada unidad?
[ ] 7. ¬øReport√© [No mencionado] cuando ausente?
[ ] 8. ¬øC√≥digos descriptivos (no abstracciones)?
[ ] 9. ¬øFormato [U#-P##] rastreable?
[ ] 10. ¬øTabla individual completa?

**SECCI√ìN 3: CODEBOOK**
[ ] 11. ¬ø4 niveles jer√°rquicos?
[ ] 12. ¬øCada c√≥digo ‚â•2 citas ‚â•2 participantes?
[ ] 13. ¬øDefiniciones operacionales?
[ ] 14. ¬øFrecuencias (N y %)?
[ ] 15. ¬øMatriz co-ocurrencias?
[ ] 16. ¬øC√≥digos excluidos reportados?
[ ] 17. ¬øCitas verbatim completas [P##-U##]?

**SECCI√ìN 4: ESTRUCTURA TEMPORAL**
[ ] 18. ¬øFases con nombres fenomenol√≥gicos?
[ ] 19. ¬øManifestaci√≥n diferenciada por estructura?
[ ] 20. ¬øTabla comparativa cuantitativa por fase?
[ ] 21. ¬øTrayectorias temporales (dynamic lines)?
[ ] 22. ¬øEventos transicionales?

**SECCI√ìN 5: CLUSTERING**
[ ] 23. ¬øClave de partici√≥n expl√≠cita?
[ ] 24. ¬øCoherencia ‚â•75% en ‚â•4/6 dimensiones?
[ ] 25. ¬øEstructuras mutuamente excluyentes?
[ ] 26. ¬øCada estructura ‚â•2 participantes?
[ ] 27. ¬øDescripci√≥n integrada?
[ ] 28. ¬øCitas ejemplares por fase?
[ ] 29. ¬øTabla comparativa (‚â•30 atributos)?
[ ] 30. ¬øSub-variantes identificadas?

**SECCI√ìN 6: VALIDACI√ìN**
[ ] 31. ¬øVerificaci√≥n exhaustiva?
[ ] 32. ¬øSaturaci√≥n calculada?
[ ] 33. ¬øCurva de saturaci√≥n?
[ ] 34. ¬øConsistencia interna?
[ ] 35. ¬øC√≥digos l√≠mite reportados?

**SECCI√ìN 7: FORMATO**
[ ] 36. ¬øMarkdown correcto?
[ ] 37. ¬øTablas con headers?
[ ] 38. ¬øLeyendas para s√≠mbolos?
[ ] 39. ¬øNegritas/cursivas consistentes?
[ ] 40. ¬øNavegable (secciones claras)?

**SECCI√ìN 8: CALIDAD CIENT√çFICA**
[ ] 41. ¬øCit√© metodolog√≠a (Giorgi, Petitmengin)?
[ ] 42. ¬øN y % en todos los hallazgos?
[ ] 43. ¬øEvit√© afirmaciones sin evidencia?
[ ] 44. ¬øDistingu√≠ robusto vs exploratorio?
[ ] 45. ¬øLimitaciones y recomendaciones?

**PUNTUACI√ìN**: [X/45]

**CRITERIO APROBACI√ìN**:
- ‚â•42/45 (93%+): EXCELENTE
- 38-41 (84-91%): BUENO
- 34-37 (76-83%): ACEPTABLE
- <34 (<76%): REQUIERE REVISI√ìN

================================================================================
FIN PARTE 3 - VALIDACI√ìN
================================================================================
"""

    return PARTE_1_EMBEDDED, PARTE_2_EMBEDDED, PARTE_3_EMBEDDED


# Cargar prompts al iniciar
PROMPT_PARTE_1, PROMPT_PARTE_2, PROMPT_PARTE_3 = load_prompt_parts()


# =============================================================================
# FUNCIONES PRINCIPALES (REESCRITAS CON PROMPTS v3.0)
# =============================================================================

def call_llm(prompt: str, system_message: str = None, temperature: float = 0.3, 
             max_tokens: int = 16000, json_mode: bool = False) -> str:
    """
    Wrapper unificado para llamadas a Claude o OpenAI.
    """
    if USE_CLAUDE:
        # Claude API
        messages = [{"role": "user", "content": prompt}]
        
        response = client.messages.create(
            model=MODEL,
            max_tokens=max_tokens,
            temperature=temperature,
            system=system_message if system_message else "You are a phenomenological analysis expert following Giorgi & Petitmengin methodology.",
            messages=messages
        )
        
        return response.content[0].text
    
    else:
        # OpenAI API
        messages = [
            {"role": "system", "content": system_message if system_message else "You are a phenomenological analysis expert."},
            {"role": "user", "content": prompt}
        ]
        
        kwargs = {
            "model": MODEL,
            "messages": messages,
            "temperature": temperature,
            "max_tokens": max_tokens
        }
        
        if json_mode:
            kwargs["response_format"] = {"type": "json_object"}
        
        response = client.chat.completions.create(**kwargs)
        return response.choices[0].message.content


def analyze_individual_interview(text: str, participant_id: str = "Pxx") -> Dict[str, Any]:
    """
    FASE 1: An√°lisis individual con prompt v3.0 completo.
    """
    
    print(f"\nüîç Analizando {participant_id}...")
    
    # Construir prompt completo
    full_prompt = f"""{PROMPT_PARTE_1}

================================================================================
AN√ÅLISIS DE PARTICIPANTE {participant_id}
================================================================================

TRANSCRIPCI√ìN ORIGINAL:

{text}

================================================================================

INSTRUCCIONES FINALES:

1. Aplica TODA la metodolog√≠a descrita en PARTE 1
2. Genera an√°lisis completo en formato JSON (usa el schema proporcionado)
3. NO omitas ninguna secci√≥n (confiabilidad, reorganizaci√≥n, tabla, estad√≠sticas, n√∫cleo)
4. S√© RIGUROSO con formatos de c√≥digos (exactamente como se especifica)
5. Reporta [No mencionado] cuando dimensi√≥n ausente (NO inventes)

RETORNA SOLO JSON V√ÅLIDO (sin preamble, sin markdown):
"""
    
    # Llamada al LLM
    response_text = call_llm(
        prompt=full_prompt,
        system_message="You are an expert in Giorgi's descriptive phenomenological method. Return ONLY valid JSON.",
        temperature=0.2,
        max_tokens=16000,
        json_mode=True
    )
    
    # Parse JSON
    try:
        result = json.loads(response_text)
        result["participant_id"] = participant_id  # Asegurar ID correcto
        print(f"‚úÖ {participant_id} analizado: {len(result.get('markdown_table', '').split('\\n'))-2} unidades identificadas")
        return result
    except json.JSONDecodeError as e:
        print(f"‚ùå Error parseando JSON para {participant_id}: {e}")
        # Fallback: devolver estructura m√≠nima
        return {
            "participant_id": participant_id,
            "error": str(e),
            "raw_response": response_text[:500]
        }


def perform_cross_case_synthesis(analyses: List[Dict[str, Any]]) -> Dict[str, Any]:
    """
    FASE 2: S√≠ntesis cross-case con prompt v3.0 completo.
    """
    
    print(f"\nüîÑ Iniciando s√≠ntesis cross-case de {len(analyses)} participantes...")
    
    # Preparar res√∫menes de an√°lisis individuales
    summaries = []
    for analysis in analyses:
        pid = analysis.get('participant_id', 'Unknown')
        nucleus = analysis.get('phenomenon_nucleus', 'N/A')
        stats = analysis.get('dimensional_statistics', {})
        
        summary = f"""
PARTICIPANTE {pid}:
- N√∫cleo fenomenol√≥gico: {nucleus}
- Estad√≠sticas dimensionales:
  * Corporal: {stats.get('corporal', {}).get('coverage', 'N/A')} cobertura
  * Afectiva: {stats.get('affective', {}).get('coverage', 'N/A')} cobertura
  * Trayectoria afectiva: {stats.get('affective', {}).get('trajectory', 'N/A')}
- Tabla de an√°lisis:
{analysis.get('markdown_table', 'N/A')[:500]}...
"""
        summaries.append(summary)
    
    combined_summary = "\n\n".join(summaries)
    
    # Construir prompt completo
    full_prompt = f"""{PROMPT_PARTE_2}

================================================================================
S√çNTESIS CROSS-CASE DE {len(analyses)} PARTICIPANTES
================================================================================

AN√ÅLISIS INDIVIDUALES:

{combined_summary}

================================================================================

INSTRUCCIONES FINALES:

1. Construye codebook emergente de 4 niveles (categor√≠a‚Üísubcategor√≠a‚Üíespecificaci√≥n‚Üíc√≥digo)
2. Valida CADA c√≥digo: ‚â•2 citas de ‚â•2 participantes
3. Identifica estructuras experienciales con coherencia ‚â•75% en ‚â•4/6 dimensiones
4. Genera estructura temporal diferenciada por perfil
5. Incluye frecuencias (N y %) en TODOS los niveles
6. Marca c√≥digos √∫nicos como "Variantes Individuales"

RETORNA SOLO JSON V√ÅLIDO (sin preamble, sin markdown):
"""
    
    # Llamada al LLM
    response_text = call_llm(
        prompt=full_prompt,
        system_message="You are an expert in phenomenological synthesis. Return ONLY valid JSON with complete codebook.",
        temperature=0.2,
        max_tokens=16000,
        json_mode=True
    )
    
    # Parse JSON
    try:
        result = json.loads(response_text)
        print(f"‚úÖ S√≠ntesis completada:")
        print(f"   - Categor√≠as: {len(result.get('codebook', {}).get('categories', []))}")
        print(f"   - Estructuras: {len(result.get('experiential_structures', []))}")
        print(f"   - Fases temporales: {len(result.get('differentiated_temporal_structure', []))}")
        return result
    except json.JSONDecodeError as e:
        print(f"‚ùå Error parseando JSON de s√≠ntesis: {e}")
        return {
            "error": str(e),
            "raw_response": response_text[:500]
        }


def perform_validation(synthesis_result: Dict[str, Any], 
                      individual_analyses: List[Dict[str, Any]]) -> Dict[str, Any]:
    """
    FASE 3: Validaci√≥n completa con prompt v3.0.
    """
    
    print(f"\n‚úì Iniciando validaci√≥n final...")
    
    # Preparar datos para validaci√≥n
    codebook_summary = json.dumps(synthesis_result.get('codebook', {}), indent=2)[:2000]
    structures_summary = json.dumps(synthesis_result.get('experiential_structures', []), indent=2)[:1000]
    
    full_prompt = f"""{PROMPT_PARTE_3}

================================================================================
VALIDACI√ìN FINAL - {len(individual_analyses)} PARTICIPANTES
================================================================================

CODEBOOK GENERADO (primeras 2000 chars):
{codebook_summary}

ESTRUCTURAS EXPERIENCIALES:
{structures_summary}

================================================================================

INSTRUCCIONES FINALES:

1. Verifica evidencia de CADA c√≥digo individualmente
2. Calcula curva de saturaci√≥n (c√≥digos nuevos por participante)
3. Verifica consistencia interna (mutua exclusividad + co-ocurrencias)
4. Completa checklist de 45 √≠tems
5. Reporta c√≥digos de frecuencia l√≠mite (N=2 participantes)

RETORNA JSON CON:
- evidence_verification: {{c√≥digo: {{valid: bool, reason: str}}}}
- saturation_analysis: {{curve: [...], diagnosis: str}}
- internal_consistency: {{mutual_exclusivity: bool, coherent_cooccurrences: X/Y}}
- checklist_score: X/45
- quality_rating: "EXCELLENT/GOOD/ACCEPTABLE/NEEDS_REVISION"
"""
    
    response_text = call_llm(
        prompt=full_prompt,
        system_message="You are a validation expert. Return ONLY valid JSON with complete validation results.",
        temperature=0.1,  # Muy baja para validaci√≥n
        max_tokens=8000,
        json_mode=True
    )
    
    try:
        result = json.loads(response_text)
        print(f"‚úÖ Validaci√≥n completada:")
        print(f"   - Checklist: {result.get('checklist_score', '?')}/45")
        print(f"   - Calidad: {result.get('quality_rating', '?')}")
        return result
    except json.JSONDecodeError as e:
        print(f"‚ùå Error parseando validaci√≥n: {e}")
        return {"error": str(e)}


# =============================================================================
# FUNCIONES WRAPPER (Compatibilidad con c√≥digo existente)
# =============================================================================

def analyze_with_pipeline(text: str, context: Dict[str, Any] = None, 
                         custom_codes: List[Dict[str, Any]] = None) -> Dict[str, Any]:
    """
    Wrapper para an√°lisis individual (mantiene compatibilidad API).
    """
    pid = context.get('participant_id', 'Pxx') if context else 'Pxx'
    return analyze_individual_interview(text, pid)


def synthesize_structure(analyses: List[Dict[str, Any]]) -> Dict[str, Any]:
    """
    Wrapper para s√≠ntesis cross-case (mantiene compatibilidad API).
    """
    return perform_cross_case_synthesis(analyses)


def generate_final_report(individual_results: List[Dict[str, Any]], 
                         synthesis_result: Dict[str, Any],
                         validation_result: Optional[Dict[str, Any]] = None) -> str:
    """
    Genera reporte final en formato Markdown v3.0.
    """
    
    report = "# PHENOMFLOW v3.0 - REPORTE FINAL COMPLETO\n\n"
    report += f"**Fecha**: {os.getenv('REPORT_DATE', 'N/A')}\n"
    report += f"**N Participantes**: {len(individual_results)}\n"
    report += f"**Modelo usado**: {MODEL}\n\n"
    
    report += "---\n\n"
    
    # PARTE 1: S√çNTESIS CROSS-CASE
    report += "## 1. S√çNTESIS CROSS-CASE\n\n"
    
    # 1.1 Estructuras Experienciales
    report += "### 1.1 Estructuras Experienciales (Perfiles Fenomenol√≥gicos)\n\n"
    for struct in synthesis_result.get('experiential_structures', []):
        report += f"#### {struct.get('structure_name', 'N/A')}\n"
        report += f"**N**: {struct.get('n_participants', '?')} participantes\n"
        report += f"**Participantes**: {', '.join(struct.get('participants', []))}\n"
        report += f"**Descripci√≥n**: {struct.get('phenomenological_description', 'N/A')}\n\n"
    
    # 1.2 Estructura Temporal
    report += "### 1.2 Estructura Temporal Diferenciada\n\n"
    for phase in synthesis_result.get('differentiated_temporal_structure', []):
        report += f"#### {phase.get('phase_name', 'N/A')}\n"
        report += f"**Frecuencia**: {phase.get('frequency_global', '?')}\n"
        report += f"- **Manifestaci√≥n Estructura A**: {phase.get('manifestation_structure_A', {}).get('summary', 'N/A')}\n"
        report += f"- **Manifestaci√≥n Estructura B**: {phase.get('manifestation_structure_B', {}).get('summary', 'N/A')}\n\n"
    
    # 1.3 Codebook (resumen)
    report += "### 1.3 Codebook Jer√°rquico (Resumen)\n\n"
    codebook_stats = synthesis_result.get('codebook', {}).get('statistics', {})
    report += f"- Categor√≠as principales: {codebook_stats.get('n_categories', '?')}\n"
    report += f"- Subcategor√≠as: {codebook_stats.get('n_subcategories', '?')}\n"
    report += f"- Especificaciones: {codebook_stats.get('n_specifications', '?')}\n"
    report += f"- C√≥digos espec√≠ficos: {codebook_stats.get('n_codes', '?')}\n"
    report += f"- Citas totales: {codebook_stats.get('n_quotes', '?')}\n"
    report += f"- Tasa de recurrencia: {codebook_stats.get('recurrence_rate', '?')}\n\n"
    
    report += "---\n\n"
    
    # PARTE 2: AN√ÅLISIS INDIVIDUALES
    report += "## 2. AN√ÅLISIS INDIVIDUALES (Evidencia)\n\n"
    for res in individual_results:
        pid = res.get('participant_id', '?')
        report += f"### Participante {pid}\n\n"
        report += f"**N√∫cleo Fenomenol√≥gico**: {res.get('phenomenon_nucleus', 'N/A')}\n\n"
        report += "**Tabla de An√°lisis Dimensional**:\n"
        report += res.get('markdown_table', '*Tabla no disponible*') + "\n\n"
        report += f"**Estad√≠sticas**:\n"
        stats = res.get('dimensional_statistics', {})
        for dim, data in stats.items():
            report += f"- {dim.capitalize()}: {data.get('coverage', '?')} cobertura\n"
        report += "\n---\n\n"
    
    # PARTE 3: VALIDACI√ìN
    if validation_result:
        report += "## 3. VALIDACI√ìN FINAL\n\n"
        report += f"**Checklist**: {validation_result.get('checklist_score', '?')}/45\n"
        report += f"**Calidad**: {validation_result.get('quality_rating', '?')}\n"
        report += f"**Saturaci√≥n**: {validation_result.get('saturation_analysis', {}).get('diagnosis', 'N/A')}\n"
        report += f"**Consistencia**: {validation_result.get('internal_consistency', {}).get('summary', 'N/A')}\n\n"
    
    return report


# =============================================================================
# FUNCI√ìN PRINCIPAL (Pipeline Completo)
# =============================================================================

def run_complete_pipeline(transcripts: List[Dict[str, str]], 
                         output_dir: str = "./analysis_results") -> str:
    """
    Ejecuta pipeline completo v3.0:
    1. An√°lisis individual de todos los participantes
    2. S√≠ntesis cross-case
    3. Validaci√≥n
    4. Generaci√≥n de reporte final
    
    Args:
        transcripts: Lista de dicts con 'participant_id' y 'text'
        output_dir: Directorio para guardar resultados
    
    Returns:
        Path al reporte final generado
    """
    
    print("\n" + "="*80)
    print("PHENOMFLOW v3.0 - PIPELINE COMPLETO")
    print("="*80)
    
    # FASE 1: An√°lisis Individual
    print("\nüìã FASE 1: AN√ÅLISIS INDIVIDUAL")
    individual_results = []
    for t in transcripts:
        result = analyze_individual_interview(t['text'], t['participant_id'])
        individual_results.append(result)
    
    # FASE 2: S√≠ntesis Cross-Case
    print("\nüîÑ FASE 2: S√çNTESIS CROSS-CASE")
    synthesis_result = perform_cross_case_synthesis(individual_results)
    
    # FASE 3: Validaci√≥n
    print("\n‚úì FASE 3: VALIDACI√ìN")
    validation_result = perform_validation(synthesis_result, individual_results)
    
    # Generar reporte final
    print("\nüìÑ GENERANDO REPORTE FINAL...")
    report_content = generate_final_report(individual_results, synthesis_result, validation_result)
    
    # Guardar reporte
    os.makedirs(output_dir, exist_ok=True)
    report_path = os.path.join(output_dir, "PHENOMFLOW_v3_REPORT_FINAL.md")
    
    with open(report_path, "w", encoding="utf-8") as f:
        f.write(report_content)
    
    print(f"\n‚úÖ PIPELINE COMPLETADO")
    print(f"üìÅ Reporte guardado en: {report_path}")
    print("="*80 + "\n")
    
    return report_path


# =============================================================================
# EJEMPLO DE USO
# =============================================================================

if __name__ == "__main__":
    # Ejemplo de uso con 2 transcripciones
    transcripts = [
        {
            "participant_id": "P21",
            "text": open("../data/transcripts/formatted_interview_P21.txt").read()
        },
        {
            "participant_id": "P27",
            "text": open("../data/transcripts/formatted_interview_P27.txt").read()
        }
    ]
    
    report_path = run_complete_pipeline(transcripts)
    print(f"Reporte disponible en: {report_path}")
